{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('DailyDelhiClimateTrain.csv')\n",
    "dataset['date']=pd.to_datetime(dataset['date'])\n",
    "\n",
    "dataset=dataset[['date','meantemp','humidity','wind_speed','meanpressure']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(0.7*len(dataset))\n",
    "train_data,val_data=dataset[:train_size],dataset[train_size:]\n",
    "val_dates=dataset['date'][train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.drop(columns=['date']).values\n",
    "val_data=val_data.drop(columns=['date']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import OneHotEncoder\\nct=ColumnTransformer(transformers=[('encoder1',OneHotEncoder(),[4])],remainder='passthrough')\\ntrain_data=ct.fit_transform(train_data)\\ntest_data=ct.fit_transform(test_data)\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct=ColumnTransformer(transformers=[('encoder1',OneHotEncoder(),[4])],remainder='passthrough')\n",
    "train_data=ct.fit_transform(train_data)\n",
    "test_data=ct.fit_transform(test_data)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10.           84.5           0.         1015.66666667]\n",
      "[  24.75   56.      4.4  1012.25]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(val_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "scaled_train_data=sc.fit_transform(train_data[:,0:])\n",
    "scaled_test_data=sc.transform(val_data[:,0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 4)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(data,timestep=1):\n",
    "    X,Y=[],[]\n",
    "    for i in range(len(data)-timestep-1):\n",
    "        X.append(scaled_train_data[i:(i+timestep)])\n",
    "        Y.append(scaled_train_data[(i+timestep)])    \n",
    "    return np.array(X),np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep=7\n",
    "x_train,y_train=create_input(scaled_train_data,timestep)\n",
    "x_test,y_test=create_input(scaled_test_data,timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2])\n",
    "#x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "y_train=y_train.astype(np.float32)\n",
    "y_test=y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1015, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.tensor(x_train).float()\n",
    "x_test=torch.tensor(x_test).float()\n",
    "y_train=torch.tensor(y_train).float()\n",
    "y_test=torch.tensor(y_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1015, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size=4,num_layers=2,hidden_size=128,batch_first=True,bidirectional=True)\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.linear1=nn.Linear(128*2,64)\n",
    "        self.linear2=nn.Linear(64,8)\n",
    "        self.output_layer=nn.Linear(8,4)\n",
    "    def forward(self,x):\n",
    "        h0=torch.zeros(self.lstm.num_layers*2,x.size(0),self.lstm.hidden_size).to(device)\n",
    "        c0=torch.zeros(self.lstm.num_layers*2,x.size(0),self.lstm.hidden_size).to(device)\n",
    "        out,_=self.lstm(x,(h0,c0))\n",
    "        out=self.dropout(out)\n",
    "        out=self.linear1(out[:,-1,:])\n",
    "        out=self.linear2(out)\n",
    "        out=self.output_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "model=LSTM()\n",
    "loss_fn=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "scheduler=ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.00742 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00795 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 2 | Loss: 0.00753 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00786 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 3 | Loss: 0.00734 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00777 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 4 | Loss: 0.00740 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00790 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 5 | Loss: 0.00724 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00791 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 6 | Loss: 0.00734 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00783 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 7 | Loss: 0.00734 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00770 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 8 | Loss: 0.00731 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00777 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 9 | Loss: 0.00736 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00769 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 10 | Loss: 0.00727 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00787 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 11 | Loss: 0.00741 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00766 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 12 | Loss: 0.00735 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00793 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 13 | Loss: 0.00732 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00780 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 14 | Loss: 0.00747 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00786 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 15 | Loss: 0.00731 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00787 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 16 | Loss: 0.00725 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00781 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 17 | Loss: 0.00724 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00769 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 18 | Loss: 0.00737 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00758 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 19 | Loss: 0.00737 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00782 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n",
      "Epoch: 20 | Loss: 0.00725 | Accuracy: tensor([1., 1., 1., 1.]) | Overall Accuracy : 100.0 | Test Loss: 0.00777 | Test Accuracy :tensor([1., 1., 1., 1.]) | Overall Test Accuracy : 100.0\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "threshold=1\n",
    "for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    y_logits=model(x_train).squeeze()\n",
    "    y_pred=torch.round(torch.sigmoid(y_logits))\n",
    "    #print(y_logits.shape)\n",
    "    loss=loss_fn(y_logits,y_train)\n",
    "    acc=torch.mean((torch.abs(y_train - y_pred) <= threshold).float(), dim=0)\n",
    "    overall_accuracy = acc.mean().item() * 100  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    test_pred=model(x_test)\n",
    "    test_loss=loss_fn(test_pred,y_test)\n",
    "    acc_test=torch.mean((torch.abs(y_test - test_pred) <= threshold).float(), dim=0)\n",
    "    overall_test_accuracy = acc_test.mean().item() * 100\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Accuracy: {acc} | Overall Accuracy : {overall_accuracy} | Test Loss: {test_loss:.5f} | Test Accuracy :{acc_test} | Overall Test Accuracy : {overall_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
