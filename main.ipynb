{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Description:**\n",
    "\n",
    "The Weather Forecast Prediction project is focused on building a deep learning model using Long Short-Term Memory (LSTM) networks to predict weather conditions based on historical meteorological data. This project employs PyTorch as the deep learning framework, leveraging its flexibility and powerful tools to design, train, and evaluate the LSTM model. The goal is to predict future weather conditions by analyzing patterns in the past weather data, specifically focusing on four key features: mean temperature, humidity, wind speed, and atmospheric pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was imported from kaggle website. It consists of many independent features like mean_temp,mean_pressure,wind speed, Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference: \n",
    "https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=pd.read_csv('DailyDelhiClimateTrain.csv')\n",
    "dataset2['date']=pd.to_datetime(dataset2['date'])\n",
    "\n",
    "dataset=dataset2[['date','meantemp','humidity','wind_speed','meanpressure']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split into Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=int(0.7*len(dataset))\n",
    "train_data,val_data=dataset[:train_size],dataset[train_size:]\n",
    "val_dates=dataset2['date'][train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we may no need of predicting dates which are sequential all over the dataset.So let's drop date column from dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "scaled_train_data=sc.fit_transform(train_data[:,1:])\n",
    "scaled_val_data=sc.transform(val_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create Inputs for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(data,timestep=1):\n",
    "    X,Y=[],[]\n",
    "    for i in range(len(data)-timestep-1):\n",
    "        X.append(scaled_train_data[i:(i+timestep)])\n",
    "        Y.append(scaled_train_data[(i+timestep)])    \n",
    "    return np.array(X),np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep=7\n",
    "x_train,y_train=create_input(scaled_train_data,timestep)\n",
    "x_val,y_val=create_input(scaled_val_data,timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our dataset is in numpy form. To input them in to a pytorch model they must be in torch tensors. So let's change numpy inputs into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "x_val = x_val.astype(np.float32)\n",
    "y_train=y_train.astype(np.float32)\n",
    "y_val=y_val.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.tensor(x_train).float()\n",
    "x_val=torch.tensor(x_val).float()\n",
    "y_train=torch.tensor(y_train).float()\n",
    "y_val=torch.tensor(y_val).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Build a Model\n",
    " Hence we are building a model to predict weather forecast which depends on their previous values we must use Recurrent neural Networks(RNN). But a simple RNN may not perform as good as well in a less number of epochs. So, let's choose LSTM.Let's also make our LSTM bidirectional so that while learning our model will learn features in both directions.We also implement dropout which helps in prevention of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size=4,num_layers=2,hidden_size=128,batch_first=True,bidirectional=True)\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.linear1=nn.Linear(128*2,64)\n",
    "        self.linear2=nn.Linear(64,8)\n",
    "        self.output_layer=nn.Linear(8,4)\n",
    "    def forward(self,x):\n",
    "        h0=torch.zeros(self.lstm.num_layers*2,x.size(0),self.lstm.hidden_size).to(device)\n",
    "        c0=torch.zeros(self.lstm.num_layers*2,x.size(0),self.lstm.hidden_size).to(device)\n",
    "        out,_=self.lstm(x,(h0,c0))\n",
    "        out=self.dropout(out)\n",
    "        out=self.linear1(out[:,-1,:])\n",
    "        out=self.linear2(out)\n",
    "        out=self.output_layer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we are going to predict numerical values which comes under regression tasks MSELoss() will be suitable and Adam optimizer plays a crucial role in optimizing values for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejat\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "model=LSTM()\n",
    "loss_fn=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "scheduler=ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our model for 20 epochs and also caluculate accuracy for every epoch for both training and validation data with a threshold range of 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.28206 | Accuracy: tensor([0.9970, 0.9921, 0.9990, 0.9901]) | Overall Accuracy : 99.45812821388245 | Validation Loss: 0.09214 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 2 | Loss: 0.08540 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 4.35315 | Validation Accuracy :tensor([0.0000, 0.0000, 0.0000, 0.1763]) | Overall Validation Accuracy : 4.408352822065353\n",
      "Epoch: 3 | Loss: 4.34537 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.05535 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 4 | Loss: 0.06226 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.23699 | Validation Accuracy :tensor([0.9884, 0.9907, 0.9954, 1.0000]) | Overall Validation Accuracy : 99.36195015907288\n",
      "Epoch: 5 | Loss: 0.23129 | Accuracy: tensor([0.9970, 0.9921, 0.9990, 0.9901]) | Overall Accuracy : 99.45812821388245 | Validation Loss: 0.26535 | Validation Accuracy :tensor([0.9884, 0.9559, 0.9954, 1.0000]) | Overall Validation Accuracy : 98.49187731742859\n",
      "Epoch: 6 | Loss: 0.25623 | Accuracy: tensor([0.9970, 0.9882, 0.9990, 0.9901]) | Overall Accuracy : 99.3596076965332 | Validation Loss: 0.25000 | Validation Accuracy :tensor([0.9930, 0.9791, 0.9954, 1.0000]) | Overall Validation Accuracy : 99.18793439865112\n",
      "Epoch: 7 | Loss: 0.24122 | Accuracy: tensor([0.9970, 0.9921, 0.9990, 0.9901]) | Overall Accuracy : 99.45812821388245 | Validation Loss: 0.22681 | Validation Accuracy :tensor([0.9977, 1.0000, 0.9954, 1.0000]) | Overall Validation Accuracy : 99.82598423957825\n",
      "Epoch: 8 | Loss: 0.21886 | Accuracy: tensor([0.9970, 0.9921, 0.9990, 0.9901]) | Overall Accuracy : 99.45812821388245 | Validation Loss: 0.19270 | Validation Accuracy :tensor([1.0000, 1.0000, 0.9954, 1.0000]) | Overall Validation Accuracy : 99.88399147987366\n",
      "Epoch: 9 | Loss: 0.18766 | Accuracy: tensor([0.9970, 0.9921, 0.9990, 0.9901]) | Overall Accuracy : 99.45812821388245 | Validation Loss: 0.13416 | Validation Accuracy :tensor([1.0000, 1.0000, 0.9977, 1.0000]) | Overall Validation Accuracy : 99.94199275970459\n",
      "Epoch: 10 | Loss: 0.13155 | Accuracy: tensor([0.9970, 0.9921, 0.9488, 0.9901]) | Overall Accuracy : 98.20197224617004 | Validation Loss: 0.07764 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 11 | Loss: 0.07646 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.14871 | Validation Accuracy :tensor([1.0000, 0.9490, 1.0000, 1.0000]) | Overall Validation Accuracy : 98.72390031814575\n",
      "Epoch: 12 | Loss: 0.14336 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.05092 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 13 | Loss: 0.05623 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.06440 | Validation Accuracy :tensor([1.0000, 1.0000, 0.9977, 1.0000]) | Overall Validation Accuracy : 99.94199275970459\n",
      "Epoch: 14 | Loss: 0.06855 | Accuracy: tensor([0.9970, 0.9921, 0.6995, 0.9901]) | Overall Accuracy : 91.97044372558594 | Validation Loss: 0.06913 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 15 | Loss: 0.06717 | Accuracy: tensor([0.9970, 0.9921, 0.6995, 0.9901]) | Overall Accuracy : 91.97044372558594 | Validation Loss: 0.06344 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 16 | Loss: 0.05531 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.06815 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 17 | Loss: 0.05599 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.07731 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 18 | Loss: 0.06305 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.06362 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 19 | Loss: 0.05154 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.04284 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n",
      "Epoch: 20 | Loss: 0.03663 | Accuracy: tensor([0.9970, 0.9921, 0.6956, 0.9901]) | Overall Accuracy : 91.8719232082367 | Validation Loss: 0.04027 | Validation Accuracy :tensor([1., 1., 1., 1.]) | Overall Validation Accuracy : 100.0\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "threshold=0.9\n",
    "def inverse_transform(data, scaler):\n",
    "    return sc.inverse_transform(data.reshape(1, -1)).flatten()\n",
    "for epoch in range(1,epochs+1):\n",
    "    model.train()\n",
    "    y_logits=model(x_train).squeeze()\n",
    "    y_pred=torch.round(torch.sigmoid(y_logits))\n",
    "    #print(y_logits.shape)\n",
    "    loss=loss_fn(y_logits,y_train)\n",
    "    acc=torch.mean((torch.abs(y_train - y_pred) <= threshold).float(), dim=0)\n",
    "    overall_accuracy = acc.mean().item() * 100  \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    val_pred=model(x_val)\n",
    "    val_loss=loss_fn(val_pred,y_val)\n",
    "    acc_val=torch.mean((torch.abs(y_val - val_pred) <= threshold).float(), dim=0)\n",
    "    overall_val_accuracy = acc_val.mean().item() * 100\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Accuracy: {acc} | Overall Accuracy : {overall_accuracy} | Validation Loss: {val_loss:.5f} | Validation Accuracy :{acc_val} | Overall Validation Accuracy : {overall_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved a training accuracy of 91.87 and validation accuracy of 100%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
